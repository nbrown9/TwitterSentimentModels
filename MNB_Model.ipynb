{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNB Sentiment Scoring Model\n",
    "\n",
    "<p> This is a process for training a Multinomial Naive Bayes sentiment classification model using tweets from a Kaggle competition. The trained model will be saved and exported at the end for reuse. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import itemfreq\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Training and Test Data\n",
    "\n",
    "#### Our training data consists of the following attributes:\n",
    "<ul> \n",
    "    <li><b>target:</b> the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)</li>\n",
    "    <li><b>ids:</b> The id of the tweet ( 2087)</li>\n",
    "    <li><b>date:</b> the date of the tweet (Sat May 16 23:58:44 UTC 2009)</li>\n",
    "    <li><b>flag:</b> The query (lyx). If there is no query, then this value is NO_QUERY.</li>\n",
    "    <li><b>user:</b> the user that tweeted (robotickilldozr)</li>\n",
    "    <li><b>text:</b> the text of the tweet (Lyx is cool)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"training_XL.csv\"\n",
    "data_set = pd.read_csv(filename, delimiter=',', encoding='ISO-8859-1', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1978075676</td>\n",
       "      <td>Sat May 30 22:22:47 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>JaySkillz</td>\n",
       "      <td>@MISSCOKASPLASH You left me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2015775002</td>\n",
       "      <td>Wed Jun 03 05:29:19 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>hayleydoherty88</td>\n",
       "      <td>Its to warm  i dnt want to work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1676588874</td>\n",
       "      <td>Fri May 01 22:30:41 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>teddybeans</td>\n",
       "      <td>Chicken rice for lunch  Oops I'm so full.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1972211695</td>\n",
       "      <td>Sat May 30 08:47:24 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Shoko_RDJ</td>\n",
       "      <td>Good night, tweeters! I really enjoyed with Tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2324163367</td>\n",
       "      <td>Thu Jun 25 02:27:15 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ambykyns</td>\n",
       "      <td>Listen to &amp;quot;Weightless&amp;quot; by All Time L...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1978075676  Sat May 30 22:22:47 PDT 2009  NO_QUERY   \n",
       "1       0  2015775002  Wed Jun 03 05:29:19 PDT 2009  NO_QUERY   \n",
       "2       4  1676588874  Fri May 01 22:30:41 PDT 2009  NO_QUERY   \n",
       "3       4  1972211695  Sat May 30 08:47:24 PDT 2009  NO_QUERY   \n",
       "4       0  2324163367  Thu Jun 25 02:27:15 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0        JaySkillz                       @MISSCOKASPLASH You left me   \n",
       "1  hayleydoherty88                    Its to warm  i dnt want to work  \n",
       "2       teddybeans          Chicken rice for lunch  Oops I'm so full.  \n",
       "3        Shoko_RDJ  Good night, tweeters! I really enjoyed with Tw...  \n",
       "4         ambykyns  Listen to &quot;Weightless&quot; by All Time L...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.columns = [\"target\",\"ids\",\"date\",\"flag\",\"user\",\"text\"]\n",
    "#Shuffle the data (get sample frac=1 means that we will use 100% of data for sample)\n",
    "data_set = data_set.sample(frac=1).reset_index(drop=True)\n",
    "y=data_set['target'].values\n",
    "X=data_set['text'].values\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data For Holdout Test\n",
    "<p> Remember that (X = Text) and (y = Sentiment Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1072000,) (1072000,) (528000,) (528000,)\n",
      "Today is 777 days until LeakyCon 2011. Awesome number but I wish it wasn't so far away \n",
      "0\n",
      "if you want to stay on my good side......never call me a skinny mini......I'm not skinny...yet like five people called me that last night \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "print(X_test[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 4}\n",
      "(array([0, 4]), array([535907, 536093]))\n"
     ]
    }
   ],
   "source": [
    "training_labels = set(y_train)\n",
    "print(training_labels)\n",
    "training_category_dist = np.unique(y_train, return_counts=True)\n",
    "print(training_category_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  unigram boolean vectorizer, set minimum document frequency to 5\n",
    "unigram_bool_vectorizer = CountVectorizer(encoding='latin-1', binary=True, min_df=5, stop_words='english')\n",
    "\n",
    "#  unigram term frequency vectorizer, set minimum document frequency to 5\n",
    "unigram_count_vectorizer = CountVectorizer(encoding='latin-1', binary=False, min_df=5, stop_words='english')\n",
    "\n",
    "#  unigram and bigram term frequency vectorizer, set minimum document frequency to 5\n",
    "gram12_count_vectorizer = CountVectorizer(encoding='latin-1', ngram_range=(1,3), min_df=5, stop_words='english')\n",
    "\n",
    "#  unigram tfidf vectorizer, set minimum document frequency to 5\n",
    "unigram_tfidf_vectorizer = TfidfVectorizer(encoding='latin-1',ngram_range=(1,2), use_idf=True, min_df=5, stop_words='english')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1072000, 43890)\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "43890\n",
      "[('today', 37715), ('days', 8151), ('2011', 273), ('awesome', 2432), ('number', 26735), ('wish', 42015), ('wasn', 40946), ('far', 11162), ('away', 2390), ('wish wasn', 42140)]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# fit vocabulary in training documents and transform the training documents into vectors\n",
    "X_train_vec = unigram_tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_vec = unigram_tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# check the content of a document vector\n",
    "print(X_train_vec.shape)\n",
    "print(X_train_vec[0].toarray())\n",
    "\n",
    "# check the size of the constructed vocabulary\n",
    "print(len(unigram_tfidf_vectorizer.vocabulary_))\n",
    "\n",
    "# print out the first 10 items in the vocabulary\n",
    "print(list(unigram_tfidf_vectorizer.vocabulary_.items())[:10])\n",
    "\n",
    "# check word index in vocabulary\n",
    "print(unigram_tfidf_vectorizer.vocabulary_.get('imaginative'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the MNB Model\n",
    "\n",
    "#### Trouble breaking 77% Hold-out test accuracy, need 85% for production, try linear SVM or Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the MNB model\n",
    "nb_clf= MultinomialNB()\n",
    "# use the training data to train the MNB model\n",
    "nb_clf.fit(X_train_vec,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-5.805283421832247, 'going'), (-5.73048122845228, 'don'), (-5.720766057254302, 'want'), (-5.716469713293092, 'like'), (-5.711298223467692, 'sad'), (-5.701307746588295, 'day'), (-5.691856625972877, 'today'), (-5.532478613221889, 'miss'), (-5.400672233724215, 'just'), (-5.349361938377399, 'work')]\n",
      "\n",
      " [(-14.150878430997022, '000 contacts'), (-14.150878430997022, '15 11'), (-14.150878430997022, '1cp2'), (-14.150878430997022, '1cp2 follow'), (-14.150878430997022, '4officeautomation'), (-14.150878430997022, '4officeautomation com'), (-14.150878430997022, '6dvj4'), (-14.150878430997022, '6g55n'), (-14.150878430997022, 'account peace'), (-14.150878430997022, 'add train')]\n"
     ]
    }
   ],
   "source": [
    "feature_ranks = sorted(zip(nb_clf.feature_log_prob_[0], unigram_tfidf_vectorizer.get_feature_names()))\n",
    "very_negative_features = feature_ranks[-10:]\n",
    "v_pos_f = feature_ranks[:10]\n",
    "print(very_negative_features)\n",
    "print('\\n',v_pos_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7678371212121212"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clf.score(X_test_vec,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
